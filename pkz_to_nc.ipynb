{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao verificar integridade do arquivo PKZ: invalid load key, '\\x00'.\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import pickle\n",
    "\n",
    "def check_pkz_integrity(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            compressed_data = f.read()\n",
    "            uncompressed_data = zlib.decompress(compressed_data)\n",
    "            # Tente desserializar os dados\n",
    "            _ = pickle.loads(uncompressed_data)\n",
    "        print(\"O arquivo PKZ está íntegro.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar integridade do arquivo PKZ: {str(e)}\")\n",
    "\n",
    "# Substitua 'caminho/para/seu/arquivo.pkz' pelo caminho real para o seu arquivo PKZ.\n",
    "check_pkz_integrity('/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/spin21.pkz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 2\u001b[0m line \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/output_folder\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m    dt \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fh)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    \u001b[39mprint\u001b[39m(dt\u001b[39m.\u001b[39mkeys()) \u001b[39m# list the available keys for the ouputs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m    \u001b[39m# 'calendar', 'time_unit', 'sind', 'eind'\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'x'."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "import datetime\n",
    "import joblib\n",
    "import cftime\n",
    "\n",
    "file_path = '/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/spin21.pkz'\n",
    "pkz_folder = '/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/'\n",
    "output_folder = '/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/output_folder'\n",
    "\n",
    "with open(file_path, 'rb') as fh:\n",
    "   dt = pickle.load(fh)\n",
    "   \n",
    "   print(dt.keys()) # list the available keys for the ouputs\n",
    "   # 'calendar', 'time_unit', 'sind', 'eind'\n",
    "   print(dt['calendar'])\n",
    "   print(dt['time_unit'])\n",
    "   print(dt['sind'])\n",
    "   print(dt['eind'])\n",
    "\n",
    "def load_pkz(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    data = pickle.loads(zlib.decompress(compressed_data))\n",
    "    return data\n",
    "\n",
    "def create_lband(res=0.5):\n",
    "    #creates an array of longitudes based on a spacing of res. that is 0.5º\n",
    "    lon = np.arange(-179.75, 180, res, dtype=np.float64)[201:272]\n",
    "    lat = np.arange(89.75, -90, -res, dtype=np.float64)[160:221][::-1]\n",
    "\n",
    "    #defines the lower and upper bounds of each latitude band. \n",
    "    half = res / 2.0\n",
    "\n",
    "    #the following vars refer to the latitude and longitude \n",
    "    # intervals associated with each specific point in a geographic grid\n",
    "    latbnd = np.array([[l - half, l + half] for l in lat])\n",
    "    lonbnd = np.array([[l - half, l + half] for l in lon])\n",
    "    \n",
    "    return lat, latbnd, lon, lonbnd\n",
    "\n",
    "def set_historical_stime(new_descr=True):\n",
    "\n",
    "    global TIME_UNITS, CALENDAR\n",
    "    TIME_UNITS = \"days since 1860-01-01 00:00:00\"\n",
    "    CALENDAR = \"proleptic_gregorian\"\n",
    "\n",
    "def get_var_metadata(var):\n",
    "\n",
    "    vunits = {'header': ['long_name', 'unit', 'standart_name'],\n",
    "\n",
    "              'tsoil': ['soil_temperature', 'celcius', 'soil_temp'],\n",
    "              'emaxm': ['potent. evapotrasnpiration', 'kg m-2 day-1', 'etpot'],\n",
    "              'aresp': ['autothrophic respiration', 'kg m-2 year-1', 'ar'],\n",
    "              'photo': ['gross primary productivity', 'kg m-2 year-1', 'gpp'],\n",
    "              'npp': ['net primary productivity', 'kg m-2 year-1', 'npp'],\n",
    "              'cawood': ['C in woody tissues', 'kg m-2', 'cawood'],\n",
    "              'cfroot': ['C in fine roots', 'kg m-2', 'cfroot'],\n",
    "              'cleaf': ['C in leaves', 'kg m-2', 'cleaf']}\n",
    "\n",
    "    out = {}\n",
    "    for v in var:\n",
    "        out[v] = vunits[v]\n",
    "    return out\n",
    "\n",
    "# Função para converter dados de PKZ para NetCDF\n",
    "def convert_pkz_to_netcdf(pkz_folder, output_folder):\n",
    "    \n",
    "    \n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    set_historical_stime()\n",
    "\n",
    "    NO_DATA = [-9999.0]\n",
    "    time_units = \"days since 1860-01-01 00:00:00\"\n",
    "    calendar = \"proleptic_gregorian\"\n",
    "   \n",
    "    #prepare lat/lon\n",
    "    geo_v = create_lband()\n",
    "    lat = geo_v[0]\n",
    "    lat_bnds = geo_v[1]\n",
    "    lon = geo_v[2]\n",
    "    lon_bnds = geo_v[3]\n",
    "\n",
    "    # Variáveis (from pkz file)\n",
    "    variables = ['emaxm', 'tsoil', 'photo', 'aresp', 'npp', 'cleaf', 'cawood', 'cfroot']\n",
    "\n",
    "    # Resolução da grade\n",
    "    resolucao = 0.5\n",
    "\n",
    "    # Calcula o número total de pontos de grade\n",
    "    num_latitudes = len(lat)\n",
    "    num_longitudes = len(lon)\n",
    "\n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    var_attrs = get_var_metadata(variables)\n",
    "\n",
    "    for i, v in enumerate(variables):\n",
    "        \n",
    "        nc_filename = os.path.join(output_folder, f\"{v}.nc\")\n",
    "        with Dataset(nc_filename, 'w', format='NETCDF4') as nc:\n",
    "\n",
    "    #         # Dimensões e variáveis\n",
    "            nc.createDimension('time', None)\n",
    "            nc.createDimension('lat', num_latitudes)\n",
    "            nc.createDimension('lon', num_longitudes)\n",
    "\n",
    "            time_var = nc.createVariable('time', np.float64, ('time',))\n",
    "            lat_var = nc.createVariable('lat', lat.dtype, ('lat',))\n",
    "            lon_var = nc.createVariable('lon', lon.dtype, ('lon',))\n",
    "    #           # Escolhe um nome para a variável NetCDF\n",
    "            nc_var_name = f\"{v}_data\"\n",
    "            \n",
    "            data_var = nc.createVariable(nc_var_name, datatype=np.float32, dimensions = ('time', 'lat', 'lon'),\n",
    "                                         zlib=True, fill_value=NO_DATA[0], fletcher32=True) \n",
    "\n",
    "    #         # Adiciona atributos\n",
    "            time_var.units = time_units\n",
    "            time_var.calendar = calendar\n",
    "            lat_var.units = 'degrees_north'\n",
    "            lon_var.units = 'degrees_east'\n",
    "            \n",
    "            data_var.long_name = var_attrs[v][0]\n",
    "            data_var.units     = var_attrs[v][1]\n",
    "            data_var.standard_name = var_attrs[v][2]\n",
    "            data_var.missing_value = NO_DATA\n",
    "\n",
    "            # # Loop através dos arquivos PKZ\n",
    "            # for root, dirs, files in os.walk(pkz_folder):\n",
    "            #    for file in files:\n",
    "            #         if file.endswith('.pkz'):\n",
    "            #             file_path = os.path.join(root, file)\n",
    "\n",
    "                        \n",
    "            gridcell_data = load_pkz('/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/spin01.pkz')\n",
    "\n",
    "\n",
    "convert_pkz_to_netcdf(pkz_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 3\u001b[0m line \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     lon \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(parts[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lat, lon\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m convert_pkz_to_netcdf(pkz_folder, output_folder)\n",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 3\u001b[0m line \u001b[0;36mconvert_pkz_to_netcdf\u001b[0;34m(pkz_folder, output_folder)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.pkz\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     gridcell_data \u001b[39m=\u001b[39m load_pkz(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39m# Extrai as coordenadas da célula de grade do nome do arquivo ou dos metadados\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m# Substitua isso com base na sua estrutura de dados\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     lat, lon \u001b[39m=\u001b[39m extract_lat_lon_from_filename(file)\n",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 3\u001b[0m line \u001b[0;36mload_pkz\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     compressed_data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mloads(zlib\u001b[39m.\u001b[39;49mdecompress(compressed_data))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "import datetime\n",
    "\n",
    "# Função para carregar dados de um arquivo PKZ\n",
    "def load_pkz(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    data = pickle.loads(zlib.decompress(compressed_data))\n",
    "    return data\n",
    "\n",
    "# Função para converter dados de PKZ para NetCDF\n",
    "def convert_pkz_to_netcdf(pkz_folder, output_folder):\n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Variáveis\n",
    "    variables = ['photo', 'aresp', 'npp', 'lai', 'wue', 'cue', 'vcmax', 'sla', 'nupt', 'pupt', 'ls']\n",
    "\n",
    "    # Loop através das variáveis\n",
    "    for variable in variables:\n",
    "        # Inicializa o NetCDF\n",
    "        nc_filename = os.path.join(output_folder, f\"{variable}.nc\")\n",
    "        with Dataset(nc_filename, 'w', format='NETCDF4') as nc:\n",
    "            # Dimensões\n",
    "            nc.createDimension('time', None)  # Pode ser alterado para o número total de dias\n",
    "            nc.createDimension('lat', 61)     # Altere para a resolução real da grade\n",
    "            nc.createDimension('lon', 71)     # Altere para a resolução real da grade\n",
    "\n",
    "            # Variáveis\n",
    "            time_var = nc.createVariable('time', 'f8', ('time',))\n",
    "            lat_var = nc.createVariable('lat', 'f4', ('lat',))\n",
    "            lon_var = nc.createVariable('lon', 'f4', ('lon',))\n",
    "            data_var = nc.createVariable(variable, 'f4', ('time', 'lat', 'lon'), fill_value=-9999.0)\n",
    "\n",
    "            # Adiciona atributos\n",
    "            time_var.units = 'days since 1900-01-01'\n",
    "            time_var.calendar = 'gregorian'\n",
    "            lat_var.units = 'degrees_north'\n",
    "            lon_var.units = 'degrees_east'\n",
    "            data_var.units = 'your_unit'  # Substitua pelo valor real\n",
    "\n",
    "            # Loop através dos arquivos PKZ\n",
    "            for root, dirs, files in os.walk(pkz_folder):\n",
    "                for file in files:\n",
    "                    if file.endswith('.pkz'):\n",
    "                        file_path = os.path.join(root, file)\n",
    "\n",
    "                        \n",
    "                        gridcell_data = load_pkz(file_path)\n",
    "\n",
    "                        # Extrai as coordenadas da célula de grade do nome do arquivo ou dos metadados\n",
    "                        # Substitua isso com base na sua estrutura de dados\n",
    "                        lat, lon = extract_lat_lon_from_filename(file)\n",
    "\n",
    "                        # Converte as datas para números do tipo float (dias desde 1900-01-01)\n",
    "                        dates = [date2num(datetime.datetime.strptime(date_str, '%Y-%m-%d'), 'days since 1900-01-01') for date_str in gridcell_data['dates']]\n",
    "\n",
    "                        # Preenche os dados NetCDF\n",
    "                        time_var[:] = dates\n",
    "                        lat_var[:] = lat\n",
    "                        lon_var[:] = lon\n",
    "                        data_var[:, lat, lon] = gridcell_data[variable]\n",
    "\n",
    "                        print(f\"Variable {variable} processed for lat={lat}, lon={lon}\")\n",
    "\n",
    "# Função de exemplo para extrair lat e lon do nome do arquivo (ajuste conforme necessário)\n",
    "def extract_lat_lon_from_filename(file):\n",
    "    # Supondo que o nome do arquivo seja algo como \"gridcell_LAT_LON.pkz\"\n",
    "    parts = file.split('_')\n",
    "    lat = float(parts[1])\n",
    "    lon = float(parts[2].split('.')[0])\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "convert_pkz_to_netcdf(pkz_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
