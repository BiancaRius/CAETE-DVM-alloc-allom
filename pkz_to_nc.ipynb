{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao verificar integridade do arquivo PKZ: invalid load key, '\\x07'.\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import pickle\n",
    "\n",
    "def check_pkz_integrity(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            compressed_data = f.read()\n",
    "            uncompressed_data = zlib.decompress(compressed_data)\n",
    "            # Tente desserializar os dados\n",
    "            _ = pickle.loads(uncompressed_data)\n",
    "        print(\"O arquivo PKZ está íntegro.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar integridade do arquivo PKZ: {str(e)}\")\n",
    "\n",
    "# Substitua 'caminho/para/seu/arquivo.pkz' pelo caminho real para o seu arquivo PKZ.\n",
    "check_pkz_integrity('/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao desserializar os dados: invalid load key, '\\x07'.\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import pickle\n",
    "\n",
    "def check_pkz_integrity(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            compressed_data = f.read()\n",
    "            uncompressed_data = zlib.decompress(compressed_data)\n",
    "            # Tente desserializar os dados\n",
    "            _ = pickle.loads(uncompressed_data)\n",
    "        print(\"O arquivo PKZ está íntegro.\")\n",
    "    except pickle.UnpicklingError as e:\n",
    "        print(f\"Erro ao desserializar os dados: {str(e)}\")\n",
    "    except zlib.error as e:\n",
    "        print(f\"Erro ao descomprimir os dados: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro desconhecido: {str(e)}\")\n",
    "\n",
    "# Substitua 'caminho/para/seu/arquivo.pkz' pelo caminho real para o seu arquivo PKZ.\n",
    "check_pkz_integrity('/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 3\u001b[0m line \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/bianca/bianca/CAETE-alloc-allom/outputs/t1_0510/gridcell175-235/output_folder\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m    dt \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fh)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    \u001b[39mprint\u001b[39m(dt\u001b[39m.\u001b[39mkeys()) \u001b[39m# list the available keys for the ouputs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m    \u001b[39m# 'calendar', 'time_unit', 'sind', 'eind'\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'x'."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "import datetime\n",
    "import joblib\n",
    "import cftime\n",
    "\n",
    "file_path = '/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz'\n",
    "pkz_folder = '/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/'\n",
    "output_folder = '/home/bianca/bianca/CAETE-alloc-allom/outputs/t1_0510/gridcell175-235/output_folder'\n",
    "\n",
    "with open(file_path, 'rb') as fh:\n",
    "   dt = pickle.load(fh)\n",
    "   \n",
    "   print(dt.keys()) # list the available keys for the ouputs\n",
    "   # 'calendar', 'time_unit', 'sind', 'eind'\n",
    "   print(dt['calendar'])\n",
    "   print(dt['time_unit'])\n",
    "   print(dt['sind'])\n",
    "   print(dt['eind'])\n",
    "\n",
    "def load_pkz(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    data = pickle.loads(zlib.decompress(compressed_data))\n",
    "    return data\n",
    "\n",
    "def create_lband(res=0.5):\n",
    "    #creates an array of longitudes based on a spacing of res. that is 0.5º\n",
    "    lon = np.arange(-179.75, 180, res, dtype=np.float64)[201:272]\n",
    "    lat = np.arange(89.75, -90, -res, dtype=np.float64)[160:221][::-1]\n",
    "\n",
    "    #defines the lower and upper bounds of each latitude band. \n",
    "    half = res / 2.0\n",
    "\n",
    "    #the following vars refer to the latitude and longitude \n",
    "    # intervals associated with each specific point in a geographic grid\n",
    "    latbnd = np.array([[l - half, l + half] for l in lat])\n",
    "    lonbnd = np.array([[l - half, l + half] for l in lon])\n",
    "    \n",
    "    return lat, latbnd, lon, lonbnd\n",
    "\n",
    "def set_historical_stime(new_descr=True):\n",
    "\n",
    "    global TIME_UNITS, CALENDAR\n",
    "    TIME_UNITS = \"days since 1860-01-01 00:00:00\"\n",
    "    CALENDAR = \"proleptic_gregorian\"\n",
    "\n",
    "def get_var_metadata(var):\n",
    "\n",
    "    vunits = {'header': ['long_name', 'unit', 'standart_name'],\n",
    "\n",
    "              'tsoil': ['soil_temperature', 'celcius', 'soil_temp'],\n",
    "              'emaxm': ['potent. evapotrasnpiration', 'kg m-2 day-1', 'etpot'],\n",
    "              'aresp': ['autothrophic respiration', 'kg m-2 year-1', 'ar'],\n",
    "              'photo': ['gross primary productivity', 'kg m-2 year-1', 'gpp'],\n",
    "              'npp': ['net primary productivity', 'kg m-2 year-1', 'npp'],\n",
    "              'cawood': ['C in woody tissues', 'kg m-2', 'cawood'],\n",
    "              'cfroot': ['C in fine roots', 'kg m-2', 'cfroot'],\n",
    "              'cleaf': ['C in leaves', 'kg m-2', 'cleaf']}\n",
    "\n",
    "    out = {}\n",
    "    for v in var:\n",
    "        out[v] = vunits[v]\n",
    "    return out\n",
    "\n",
    "# Função para converter dados de PKZ para NetCDF\n",
    "def convert_pkz_to_netcdf(pkz_folder, output_folder):\n",
    "    \n",
    "    \n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    set_historical_stime()\n",
    "\n",
    "    NO_DATA = [-9999.0]\n",
    "    time_units = \"days since 1860-01-01 00:00:00\"\n",
    "    calendar = \"proleptic_gregorian\"\n",
    "   \n",
    "    #prepare lat/lon\n",
    "    geo_v = create_lband()\n",
    "    lat = geo_v[0]\n",
    "    lat_bnds = geo_v[1]\n",
    "    lon = geo_v[2]\n",
    "    lon_bnds = geo_v[3]\n",
    "\n",
    "    # Variáveis (from pkz file)\n",
    "    variables = ['emaxm', 'tsoil', 'photo', 'aresp', 'npp', 'cleaf', 'cawood', 'cfroot']\n",
    "\n",
    "    # Resolução da grade\n",
    "    resolucao = 0.5\n",
    "\n",
    "    # Calcula o número total de pontos de grade\n",
    "    num_latitudes = len(lat)\n",
    "    num_longitudes = len(lon)\n",
    "\n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    var_attrs = get_var_metadata(variables)\n",
    "\n",
    "    for i, v in enumerate(variables):\n",
    "        \n",
    "        nc_filename = os.path.join(output_folder, f\"{v}.nc\")\n",
    "        with Dataset(nc_filename, 'w', format='NETCDF4') as nc:\n",
    "\n",
    "    #         # Dimensões e variáveis\n",
    "            nc.createDimension('time', None)\n",
    "            nc.createDimension('lat', num_latitudes)\n",
    "            nc.createDimension('lon', num_longitudes)\n",
    "\n",
    "            time_var = nc.createVariable('time', np.float64, ('time',))\n",
    "            lat_var = nc.createVariable('lat', lat.dtype, ('lat',))\n",
    "            lon_var = nc.createVariable('lon', lon.dtype, ('lon',))\n",
    "    #           # Escolhe um nome para a variável NetCDF\n",
    "            nc_var_name = f\"{v}_data\"\n",
    "            \n",
    "            data_var = nc.createVariable(nc_var_name, datatype=np.float32, dimensions = ('time', 'lat', 'lon'),\n",
    "                                         zlib=True, fill_value=NO_DATA[0], fletcher32=True) \n",
    "\n",
    "    #         # Adiciona atributos\n",
    "            time_var.units = time_units\n",
    "            time_var.calendar = calendar\n",
    "            lat_var.units = 'degrees_north'\n",
    "            lon_var.units = 'degrees_east'\n",
    "            \n",
    "            data_var.long_name = var_attrs[v][0]\n",
    "            data_var.units     = var_attrs[v][1]\n",
    "            data_var.standard_name = var_attrs[v][2]\n",
    "            data_var.missing_value = NO_DATA\n",
    "\n",
    "            # # Loop através dos arquivos PKZ\n",
    "            # for root, dirs, files in os.walk(pkz_folder):\n",
    "            #    for file in files:\n",
    "            #         if file.endswith('.pkz'):\n",
    "            #             file_path = os.path.join(root, file)\n",
    "\n",
    "                        \n",
    "            gridcell_data = load_pkz('/home/bianca/bianca/CAETE-DVM-JP/CAETE-DVM/outputs/CAX-ISIMIP/gridcell183-257/spin01.pkz')\n",
    "\n",
    "\n",
    "convert_pkz_to_netcdf(pkz_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pkz_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 5\u001b[0m line \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     lon \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(parts[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W3sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lat, lon\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W3sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m convert_pkz_to_netcdf(pkz_folder, output_folder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pkz_folder' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "import datetime\n",
    "\n",
    "# Função para carregar dados de um arquivo PKZ\n",
    "def load_pkz(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    data = pickle.loads(zlib.decompress(compressed_data))\n",
    "    return data\n",
    "\n",
    "# Função para converter dados de PKZ para NetCDF\n",
    "def convert_pkz_to_netcdf(pkz_folder, output_folder):\n",
    "    # Certifique-se de que a pasta de saída exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Variáveis\n",
    "    variables = ['photo', 'aresp', 'npp', 'lai', 'wue', 'cue', 'vcmax', 'sla', 'nupt', 'pupt', 'ls']\n",
    "\n",
    "    # Loop através das variáveis\n",
    "    for variable in variables:\n",
    "        # Inicializa o NetCDF\n",
    "        nc_filename = os.path.join(output_folder, f\"{variable}.nc\")\n",
    "        with Dataset(nc_filename, 'w', format='NETCDF4') as nc:\n",
    "            # Dimensões\n",
    "            nc.createDimension('time', None)  # Pode ser alterado para o número total de dias\n",
    "            nc.createDimension('lat', 61)     # Altere para a resolução real da grade\n",
    "            nc.createDimension('lon', 71)     # Altere para a resolução real da grade\n",
    "\n",
    "            # Variáveis\n",
    "            time_var = nc.createVariable('time', 'f8', ('time',))\n",
    "            lat_var = nc.createVariable('lat', 'f4', ('lat',))\n",
    "            lon_var = nc.createVariable('lon', 'f4', ('lon',))\n",
    "            data_var = nc.createVariable(variable, 'f4', ('time', 'lat', 'lon'), fill_value=-9999.0)\n",
    "\n",
    "            # Adiciona atributos\n",
    "            time_var.units = 'days since 1900-01-01'\n",
    "            time_var.calendar = 'gregorian'\n",
    "            lat_var.units = 'degrees_north'\n",
    "            lon_var.units = 'degrees_east'\n",
    "            data_var.units = 'your_unit'  # Substitua pelo valor real\n",
    "\n",
    "            # Loop através dos arquivos PKZ\n",
    "            for root, dirs, files in os.walk(pkz_folder):\n",
    "                for file in files:\n",
    "                    if file.endswith('.pkz'):\n",
    "                        file_path = os.path.join(root, file)\n",
    "\n",
    "                        \n",
    "                        gridcell_data = load_pkz(file_path)\n",
    "\n",
    "                        # Extrai as coordenadas da célula de grade do nome do arquivo ou dos metadados\n",
    "                        # Substitua isso com base na sua estrutura de dados\n",
    "                        lat, lon = extract_lat_lon_from_filename(file)\n",
    "\n",
    "                        # Converte as datas para números do tipo float (dias desde 1900-01-01)\n",
    "                        dates = [date2num(datetime.datetime.strptime(date_str, '%Y-%m-%d'), 'days since 1900-01-01') for date_str in gridcell_data['dates']]\n",
    "\n",
    "                        # Preenche os dados NetCDF\n",
    "                        time_var[:] = dates\n",
    "                        lat_var[:] = lat\n",
    "                        lon_var[:] = lon\n",
    "                        data_var[:, lat, lon] = gridcell_data[variable]\n",
    "\n",
    "                        print(f\"Variable {variable} processed for lat={lat}, lon={lon}\")\n",
    "\n",
    "# Função de exemplo para extrair lat e lon do nome do arquivo (ajuste conforme necessário)\n",
    "def extract_lat_lon_from_filename(file):\n",
    "    # Supondo que o nome do arquivo seja algo como \"gridcell_LAT_LON.pkz\"\n",
    "    parts = file.split('_')\n",
    "    lat = float(parts[1])\n",
    "    lon = float(parts[2].split('.')[0])\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "convert_pkz_to_netcdf(pkz_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "255",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 5\u001b[0m line \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     df\u001b[39m.\u001b[39mto_csv(csv_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#use the function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pkz2csv(\u001b[39m'\u001b[39;49m\u001b[39m/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39moutput.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 5\u001b[0m line \u001b[0;36mpkz2csv\u001b[0;34m(file_path, csv_file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpkz2csv\u001b[39m(file_path, csv_file):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         data \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(fh)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m      \u001b[39m# Create a DataFrame from the variables\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    576\u001b[0m     \u001b[39mwith\u001b[39;00m _read_fileobject(fobj, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m--> 577\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    578\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    504\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    508\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    512\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39m)\n\u001b[1;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 255"
     ]
    }
   ],
   "source": [
    "file_path = '/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz'\n",
    "pkz_folder = '/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/'\n",
    "output_folder = '/home/bianca/bianca/CAETE-alloc-allom/outputs/t1_0510/gridcell175-235/output_folder'\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def pkz2csv(file_path, csv_file):\n",
    "    with open(file_path, 'rb') as fh:\n",
    "        data = joblib.load(fh)\n",
    "\n",
    "     # Create a DataFrame from the variables\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save DataFrame to CSV in a specific directory\n",
    "    csv_path = output_folder + csv_file\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "#use the function\n",
    "\n",
    "pkz2csv('/home/bianca/bianca/CAETE-DVM-alloc-allom/outputs/t1_0510/gridcell175-235/spin19.pkz', 'output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'caete'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb Célula 6\u001b[0m line \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bianca/bianca/CAETE-DVM-alloc-allom/pkz_to_nc.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcaete\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmod\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'caete'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import copy\n",
    "import bz2\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import joblib\n",
    "\n",
    "import caete as mod\n",
    "# import plsgen as pls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
